{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQow7ijBYmfj"
   },
   "source": [
    "# Large scale text analysis with deep learning\n",
    "# Practice (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAdneWSSYmfj"
   },
   "source": [
    "In this assignment, you will develop a deep learning model that predicts salaries based on resumes (credits to to [Oleg Vasilev](https://github.com/Omrigan/) and [Yandex Data School](https://github.com/yandexdataschool/nlp_course/tree/2024/week02_classification)). We will begin this project during our class, but it will require additional effort from you to finalize and submit it as the homework.\n",
    "\n",
    "To secure full grade for this assignment, ensure a consistent training process with an MSE loss falling below 0.10. If necessary, feel free to experiment with different parameters and model architectures. You are asked to implement at least two different architectures that reach this MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "udAO40ZtYmfk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-NRE0FoYmfk"
   },
   "source": [
    "### Data from Adzuna challenge\n",
    "For starters, let's download the data from\n",
    "1)  [google drive](https://drive.google.com/file/d/1c41JVi3so_GSQ0tPCIsmXsq_dUTSb5iZ/view?usp=sharing), or\n",
    "2) the Kaggle ompetition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`).\n",
    "\n",
    "Source: Adzuna, Andrew Hunter, Ben Hamner, Fabio, and XiaoJenna. Job Salary Prediction. https://kaggle.com/competitions/job-salary-prediction, 2013. Kaggle.\n",
    "\n",
    "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "zRieJERDt1WL"
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# gdown.download(f\"https://drive.google.com/uc?id=1c41JVi3so_GSQ0tPCIsmXsq_dUTSb5iZ\", \"Train_rev1.zip\", quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SooghvocYmfk",
    "outputId": "9eaa5088-e0ad-4427-905e-eaf3c3a0b7bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.zip\", compression='zip', index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "k5n_PGGvYmfk",
    "outputId": "e76bcc0a-3547-49b3-a7ed-7afad48ea064"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLG-WbFDYmfk"
   },
   "source": [
    "One challenge with salary prediction is its uneven distribution: while many individuals earn standard salaries, a few receive exceptionally high incomes. This results in a right-skewed, heavy-tailed distribution, which poses challenges for minimizing Mean Squared Error (MSE).\n",
    "\n",
    "Several techniques can address this issue, such as using a different loss function, predicting the logarithm of the target instead of the raw target, or replacing the targets with their percentiles within the salary distribution of the training set. For now, we will use the logarithmic transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "gZn1qjucYmfl",
    "outputId": "d8eac7de-341b-4399-bde5-e71b1869f892"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAFfCAYAAABQlzQ4AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAStxJREFUeJzt3XtYFOfZP/AvB3fBwy6iwkJBxWhEFEFR103UVyNlVZJIg6kaqsSgvvKCDaxRpLVotC0W44FElCYmYt5IPfSKJgEFCQrGiCciUVD4qcFiqgtGhVWigDC/P3yZugEVFHYZ+H6ua67LnefemXuewMyd4ZlnLARBEEBEREREJGGW5k6AiIiIiOhZsaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkedbmTsCc6urqcPXqVXTr1g0WFhbmToeI2hlBEHD79m04OzvD0rJ93kPgeZSIWltTz6Uduqi9evUqXF1dzZ0GEbVzV65cgYuLi7nTaBU8jxKRqTzpXNqhi9pu3boBeNBJCoXCzNkQUXtjMBjg6uoqnmvaI55Hiai1NfVc2qGL2vo/lSkUCp6MiajVtOc/y/M8SkSm8qRzafsc5EVEREREHQqLWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8qzNnUBH0HdparO/c3m1fytkQkREZH7NvS7ymkhNwaK2jWIhTERERNR0HH5ARERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREksc3ihEREdFTe5o3YBK1Bt6pJSIyoc2bN2Po0KFQKBRQKBTQaDTYv3+/2D5+/HhYWFgYLQsWLDDaRklJCfz9/dG5c2c4ODhg8eLFuH//vlFMVlYWhg8fDrlcjv79+yMpKalBLgkJCejbty9sbGygVqtx4sSJVjlmIiJTYFFLRGRCLi4uWL16NXJzc3Hq1Cm89NJLmDp1KgoKCsSYefPm4dq1a+ISFxcnttXW1sLf3x/V1dU4evQotm3bhqSkJMTExIgxxcXF8Pf3x4QJE5CXl4eIiAjMnTsX6enpYszOnTuh0+mwfPlyfPfdd/Dy8oJWq0VZWZlpOoKIqIWxqCUiMqFXXnkFU6ZMwYABA/D888/jL3/5C7p27Ypjx46JMZ07d4ZKpRIXhUIhth04cADnzp3DZ599Bm9vb0yePBmrVq1CQkICqqurAQCJiYlwc3PD2rVrMWjQIISHh2PatGlYv369uJ1169Zh3rx5mDNnDjw8PJCYmIjOnTvjk08+MV1nEBG1IBa1RERmUltbix07dqCyshIajUZcv337dvTs2RNDhgxBdHQ0fv75Z7EtJycHnp6ecHR0FNdptVoYDAbxbm9OTg58fX2N9qXVapGTkwMAqK6uRm5urlGMpaUlfH19xZhHqaqqgsFgMFqIiNoCPihGRGRiZ8+ehUajwb1799C1a1fs2bMHHh4eAIA33ngDffr0gbOzM86cOYOoqCgUFRXh888/BwDo9XqjghaA+Fmv1z82xmAw4O7du7h16xZqa2sbjSksLHxs7rGxsXj33Xef/uCJiFpJs+/U/vvf/8bvfvc79OjRA7a2tvD09MSpU6fEdkEQEBMTAycnJ9ja2sLX1xcXLlww2sbNmzcRFBQEhUIBOzs7hISE4M6dO0YxZ86cwdixY2FjYwNXV1ejMWX1du/eDXd3d9jY2MDT0xP79u1r7uEQEZncwIEDkZeXh+PHjyM0NBTBwcE4d+4cAGD+/PnQarXw9PREUFAQPv30U+zZsweXLl0yc9YPREdHo6KiQlyuXLli7pSIiAA0s6i9desWXnzxRXTq1An79+/HuXPnsHbtWnTv3l2MiYuLw/vvv4/ExEQcP34cXbp0gVarxb1798SYoKAgFBQUICMjAykpKTh8+DDmz58vthsMBvj5+aFPnz7Izc3FmjVrsGLFCnz44YdizNGjRzFz5kyEhITg9OnTCAgIQEBAAPLz85+lP4iIWp1MJkP//v3h4+OD2NhYeHl5IT4+vtFYtVoNALh48SIAQKVSobS01Cim/rNKpXpsjEKhgK2tLXr27AkrK6tGY+q38ShyuVycuaF+ISJqC5pV1P7tb3+Dq6srtm7dilGjRsHNzQ1+fn547rnnADy4S7thwwYsW7YMU6dOxdChQ/Hpp5/i6tWr2Lt3LwDg/PnzSEtLw5YtW6BWqzFmzBh88MEH2LFjB65evQrgwXiy6upqfPLJJxg8eDBmzJiB3//+91i3bp2YS3x8PCZNmoTFixdj0KBBWLVqFYYPH46NGze2UNcQEZlGXV0dqqqqGm3Ly8sDADg5OQEANBoNzp49azRLQUZGBhQKhTiEQaPRIDMz02g7GRkZ4rhdmUwGHx8fo5i6ujpkZmYaje0lIpKSZhW1X375JUaMGIHXX38dDg4OGDZsGD766COxvbi4GHq93ujhA6VSCbVaLT58kJOTAzs7O4wYMUKM8fX1haWlJY4fPy7GjBs3DjKZTIzRarUoKirCrVu3xJjHPQjRGD7gQETmFh0djcOHD+Py5cs4e/YsoqOjkZWVhaCgIFy6dAmrVq1Cbm4uLl++jC+//BKzZ8/GuHHjMHToUACAn58fPDw8MGvWLHz//fdIT0/HsmXLEBYWBrlcDgBYsGABfvjhByxZsgSFhYXYtGkTdu3ahcjISDEPnU6Hjz76CNu2bcP58+cRGhqKyspKzJkzxyz9QkT0rJpV1P7www/YvHkzBgwYgPT0dISGhuL3v/89tm3bBuA/Dyk09vDBww8wODg4GLVbW1vD3t7+iQ85PLyPR8XUtzcmNjYWSqVSXFxdXZtz+EREz6ysrAyzZ8/GwIEDMXHiRJw8eRLp6en49a9/DZlMhq+//hp+fn5wd3fHokWLEBgYiK+++kr8vpWVFVJSUmBlZQWNRoPf/e53mD17NlauXCnGuLm5ITU1FRkZGfDy8sLatWuxZcsWaLVaMWb69Ol47733EBMTA29vb+Tl5SEtLa3BeZWISCqaNftBXV0dRowYgb/+9a8AgGHDhiE/Px+JiYkIDg5ulQRbUnR0NHQ6nfjZYDCwsCUik/r4448f2ebq6ors7OwnbqNPnz5PfDB2/PjxOH369GNjwsPDER4e/sT9ERFJQbPu1Do5OYljtuoNGjQIJSUlAP7zkMLjHj5QqVQN3lhz//593Lx584kPOTy8j0fFPO4hBz7gQERERNQ+NauoffHFF1FUVGS07v/9v/+HPn36AHjwJy+VSmX08IHBYMDx48fFhw80Gg3Ky8uRm5srxhw8eBB1dXXiU74ajQaHDx9GTU2NGJORkYGBAweKMy086UEIIiIiIuo4mlXURkZG4tixY/jrX/+KixcvIjk5GR9++CHCwsIAABYWFoiIiMCf//xnfPnllzh79ixmz54NZ2dnBAQEAHhwZ3fSpEmYN28eTpw4gW+//Rbh4eGYMWMGnJ2dATyYfFwmkyEkJAQFBQXYuXMn4uPjjYYOvP3220hLS8PatWtRWFiIFStW4NSpU/xTGhEREVEH1KwxtSNHjsSePXsQHR2NlStXws3NDRs2bEBQUJAYs2TJElRWVmL+/PkoLy/HmDFjkJaWBhsbGzFm+/btCA8Px8SJE2FpaYnAwEC8//77YrtSqcSBAwcQFhYGHx8f9OzZEzExMUZz2b7wwgtITk7GsmXL8Ic//AEDBgzA3r17MWTIkGfpDyIiIiKSIAtBEARzJ2EuBoMBSqUSFRUVrTq+tu/S1Fbb9sMur/Y3yX6IqGlMdY4xp45wjPR4prjG8frWsTX1PNPs1+QSEREREbU1LGqJiIiISPJY1BIRERGR5DXrQTEiIiJqv0z1DAhRa+CdWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiMqHNmzdj6NChUCgUUCgU0Gg02L9/v9h+7949hIWFoUePHujatSsCAwNRWlpqtI2SkhL4+/ujc+fOcHBwwOLFi3H//n2jmKysLAwfPhxyuRz9+/dHUlJSg1wSEhLQt29f2NjYQK1W48SJE61yzEREpsCilojIhFxcXLB69Wrk5ubi1KlTeOmllzB16lQUFBQAACIjI/HVV19h9+7dyM7OxtWrV/Haa6+J36+trYW/vz+qq6tx9OhRbNu2DUlJSYiJiRFjiouL4e/vjwkTJiAvLw8RERGYO3cu0tPTxZidO3dCp9Nh+fLl+O677+Dl5QWtVouysjLTdQYRUQuyEARBMHcS5mIwGKBUKlFRUQGFQtFq++m7NLXVtv2wy6v9TbIfImqapp5j7O3tsWbNGkybNg29evVCcnIypk2bBgAoLCzEoEGDkJOTg9GjR2P//v14+eWXcfXqVTg6OgIAEhMTERUVhevXr0MmkyEqKgqpqanIz88X9zFjxgyUl5cjLS0NAKBWqzFy5Ehs3LgRAFBXVwdXV1csXLgQS5cufWSuVVVVqKqqMjpGV1fXVj+PkmmY6nrVXLy+dWxNPZfyTi0RkZnU1tZix44dqKyshEajQW5uLmpqauDr6yvGuLu7o3fv3sjJyQEA5OTkwNPTUyxoAUCr1cJgMIh3e3Nycoy2UR9Tv43q6mrk5uYaxVhaWsLX11eMeZTY2FgolUpxcXV1fbZOICJqISxqiYhM7OzZs+jatSvkcjkWLFiAPXv2wMPDA3q9HjKZDHZ2dkbxjo6O0Ov1AAC9Xm9U0Na317c9LsZgMODu3bv46aefUFtb22hM/TYeJTo6GhUVFeJy5cqVZh8/EVFrsDZ3AkREHc3AgQORl5eHiooK/POf/0RwcDCys7PNnVaTyOVyyOVyc6dBRNQAi1oiIhOTyWTo378/AMDHxwcnT55EfHw8pk+fjurqapSXlxvdrS0tLYVKpQIAqFSqBrMU1M+O8HDML2dMKC0thUKhgK2tLaysrGBlZdVoTP02iIikhsMPiIjMrK6uDlVVVfDx8UGnTp2QmZkpthUVFaGkpAQajQYAoNFocPbsWaNZCjIyMqBQKODh4SHGPLyN+pj6bchkMvj4+BjF1NXVITMzU4whIpIa3qklIjKh6OhoTJ48Gb1798bt27eRnJyMrKwspKenQ6lUIiQkBDqdDvb29lAoFFi4cCE0Gg1Gjx4NAPDz84OHhwdmzZqFuLg46PV6LFu2DGFhYeKwgAULFmDjxo1YsmQJ3nrrLRw8eBC7du1Caup/nmzX6XQIDg7GiBEjMGrUKGzYsAGVlZWYM2eOWfqFiOhZsaglIjKhsrIyzJ49G9euXYNSqcTQoUORnp6OX//61wCA9evXw9LSEoGBgaiqqoJWq8WmTZvE71tZWSElJQWhoaHQaDTo0qULgoODsXLlSjHGzc0NqampiIyMRHx8PFxcXLBlyxZotVoxZvr06bh+/TpiYmKg1+vh7e2NtLS0Bg+PERFJRbOGH6xYsQIWFhZGi7u7u9jON+EQET3exx9/jMuXL6OqqgplZWX4+uuvxYIWAGxsbJCQkICbN2+isrISn3/+eYNxrn369MG+ffvw888/4/r163jvvfdgbW18j2L8+PE4ffo0qqqqcOnSJbz55psNcgkPD8e//vUvVFVV4fjx41Cr1a1yzEREptDsMbWDBw/GtWvXxOXIkSNiG9+EQ0RERETm0Oyi1traGiqVSlx69uwJAKioqMDHH3+MdevW4aWXXoKPjw+2bt2Ko0eP4tixYwCAAwcO4Ny5c/jss8/g7e2NyZMnY9WqVUhISEB1dTWAB2/GcXNzw9q1azFo0CCEh4dj2rRpWL9+vZjDunXrMG/ePMyZMwceHh5ITExE586d8cknn7REnxARERGRxDS7qL1w4QKcnZ3Rr18/BAUFoaSkBAAk8SacqqoqGAwGo4WIiIiIpK9ZRa1arUZSUhLS0tKwefNmFBcXY+zYsbh9+7Yk3oTD1zsSERERtU/Nmv1g8uTJ4r+HDh0KtVqNPn36YNeuXbC1tW3x5FpadHQ0dDqd+NlgMLCwJSIiImoHnunlC3Z2dnj++edx8eJFqFQq8U04D/vlm3Aae4NNfdvjYurfhNOzZ8+nfhOOXC6HQqEwWoiIiIhI+p6pqL1z5w4uXboEJycnvgmHiIiIiMymWUXtO++8g+zsbFy+fBlHjx7Fb37zG1hZWWHmzJlGb8I5dOgQcnNzMWfOnEe+Cef7779Henp6o2/C+eGHH7BkyRIUFhZi06ZN2LVrFyIjI8U8dDodPvroI2zbtg3nz59HaGgo34RDRERE1IE1a0ztjz/+iJkzZ+LGjRvo1asXxowZg2PHjqFXr14A+CYcIiIianl9l6Y+OegXLq/2b4VMqC2zEARBMHcS5mIwGKBUKlFRUdGq42uf5pfxafAXmKhtMdU5xpw6wjF2JKa6XpkCr4ntR1PPM880ppaIiIiIqC1gUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIyIRiY2MxcuRIdOvWDQ4ODggICEBRUZFRzPjx42FhYWG0LFiwwCimpKQE/v7+6Ny5MxwcHLB48WLcv3/fKCYrKwvDhw+HXC5H//79kZSU1CCfhIQE9O3bFzY2NlCr1Thx4kSLHzMRkSmwqCUiMqHs7GyEhYXh2LFjyMjIQE1NDfz8/FBZWWkUN2/ePFy7dk1c4uLixLba2lr4+/ujuroaR48exbZt25CUlISYmBgxpri4GP7+/pgwYQLy8vIQERGBuXPnIj09XYzZuXMndDodli9fju+++w5eXl7QarUoKytr/Y4gImph1uZOgIioI0lLSzP6nJSUBAcHB+Tm5mLcuHHi+s6dO0OlUjW6jQMHDuDcuXP4+uuv4ejoCG9vb6xatQpRUVFYsWIFZDIZEhMT4ebmhrVr1wIABg0ahCNHjmD9+vXQarUAgHXr1mHevHmYM2cOACAxMRGpqan45JNPsHTp0tY4fCKiVsM7tUREZlRRUQEAsLe3N1q/fft29OzZE0OGDEF0dDR+/vlnsS0nJweenp5wdHQU12m1WhgMBhQUFIgxvr6+RtvUarXIyckBAFRXVyM3N9coxtLSEr6+vmJMY6qqqmAwGIwWIqK2gHdqiYjMpK6uDhEREXjxxRcxZMgQcf0bb7yBPn36wNnZGWfOnEFUVBSKiorw+eefAwD0er1RQQtA/KzX6x8bYzAYcPfuXdy6dQu1tbWNxhQWFj4y59jYWLz77rtPf9BERK2ERS0RkZmEhYUhPz8fR44cMVo/f/588d+enp5wcnLCxIkTcenSJTz33HOmTtNIdHQ0dDqd+NlgMMDV1dWMGRERPcCilojIDMLDw5GSkoLDhw/DxcXlsbFqtRoAcPHiRTz33HNQqVQNZikoLS0FAHEcrkqlEtc9HKNQKGBrawsrKytYWVk1GvOosbwAIJfLIZfLm3aQREQmxDG1REQmJAgCwsPDsWfPHhw8eBBubm5P/E5eXh4AwMnJCQCg0Whw9uxZo1kKMjIyoFAo4OHhIcZkZmYabScjIwMajQYAIJPJ4OPjYxRTV1eHzMxMMYaISEp4p5aIyITCwsKQnJyML774At26dRPHwCqVStja2uLSpUtITk7GlClT0KNHD5w5cwaRkZEYN24chg4dCgDw8/ODh4cHZs2ahbi4OOj1eixbtgxhYWHiXdQFCxZg48aNWLJkCd566y0cPHgQu3btQmpqqpiLTqdDcHAwRowYgVGjRmHDhg2orKwUZ0MgIpISFrVERCa0efNmAA9esPCwrVu34s0334RMJsPXX38tFpiurq4IDAzEsmXLxFgrKyukpKQgNDQUGo0GXbp0QXBwMFauXCnGuLm5ITU1FZGRkYiPj4eLiwu2bNkiTucFANOnT8f169cRExMDvV4Pb29vpKWlNXh4jIhICiwEQRDMnYS5GAwGKJVKVFRUQKFQtNp++i5NfXKQmVxe7W/uFIjaLVOdY8ypIxxjR9KWr1fNxetb+9HU8wzH1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpK8ZypqV69eDQsLC0RERIjr7t27h7CwMPTo0QNdu3ZFYGBgg9cwlpSUwN/fH507d4aDgwMWL16M+/fvG8VkZWVh+PDhkMvl6N+/P5KSkhrsPyEhAX379oWNjQ3UanWD10YSERERUcfw1EXtyZMn8fe//118w029yMhIfPXVV9i9ezeys7Nx9epVvPbaa2J7bW0t/P39UV1djaNHj2Lbtm1ISkpCTEyMGFNcXAx/f39MmDABeXl5iIiIwNy5c5Geni7G7Ny5EzqdDsuXL8d3330HLy8vaLVao9dGEhEREVHH8FRF7Z07dxAUFISPPvoI3bt3F9dXVFTg448/xrp16/DSSy/Bx8cHW7duxdGjR3Hs2DEAwIEDB3Du3Dl89tln8Pb2xuTJk7Fq1SokJCSguroaAJCYmAg3NzesXbsWgwYNQnh4OKZNm4b169eL+1q3bh3mzZuHOXPmwMPDA4mJiejcuTM++eSTR+ZdVVUFg8FgtBARERGR9D1VURsWFgZ/f3/4+voarc/NzUVNTY3Rend3d/Tu3Rs5OTkAgJycHHh6ehq9hlGr1cJgMKCgoECM+eW2tVqtuI3q6mrk5uYaxVhaWsLX11eMaUxsbCyUSqW4uLq6Ps3hExEREVEbY93cL+zYsQPfffcdTp482aBNr9dDJpPBzs7OaL2joyP0er0Y88v3itd/flKMwWDA3bt3cevWLdTW1jYaU1hY+Mjco6OjodPpxM8Gg4GFLRERtUvt6ZW3RE3RrKL2ypUrePvtt5GRkQEbG5vWyqnVyOVyyOVyc6dBRERERC2sWcMPcnNzUVZWhuHDh8Pa2hrW1tbIzs7G+++/D2trazg6OqK6uhrl5eVG3ystLYVKpQIAqFSqBrMh1H9+UoxCoYCtrS169uwJKyurRmPqt0FEREREHUezitqJEyfi7NmzyMvLE5cRI0YgKChI/HenTp2QmZkpfqeoqAglJSXQaDQAAI1Gg7NnzxrNUpCRkQGFQgEPDw8x5uFt1MfUb0Mmk8HHx8copq6uDpmZmWIMEREREXUczRp+0K1bNwwZMsRoXZcuXdCjRw9xfUhICHQ6Hezt7aFQKLBw4UJoNBqMHj0aAODn5wcPDw/MmjULcXFx0Ov1WLZsGcLCwsShAQsWLMDGjRuxZMkSvPXWWzh48CB27dqF1NT/jA/S6XQIDg7GiBEjMGrUKGzYsAGVlZWYM2fOM3UIEREREUlPsx8Ue5L169fD0tISgYGBqKqqglarxaZNm8R2KysrpKSkIDQ0FBqNBl26dEFwcDBWrlwpxri5uSE1NRWRkZGIj4+Hi4sLtmzZAq1WK8ZMnz4d169fR0xMDPR6Pby9vZGWltbg4TEiIiIiav8sBEEQzJ2EuRgMBiiVSlRUVEChULTaftryE6iXV/ubOwWidstU5xhz6gjHKFVt+dpjCry+tR9NPc8802tyiYiIiIjaAha1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIjKh2NhYjBw5Et26dYODgwMCAgJQVFRkFHPv3j2EhYWhR48e6Nq1KwIDA1FaWmoUU1JSAn9/f3Tu3BkODg5YvHgx7t+/bxSTlZWF4cOHQy6Xo3///khKSmqQT0JCAvr27QsbGxuo1WqcOHGixY+ZiMgUWNQSEZlQdnY2wsLCcOzYMWRkZKCmpgZ+fn6orKwUYyIjI/HVV19h9+7dyM7OxtWrV/Haa6+J7bW1tfD390d1dTWOHj2Kbdu2ISkpCTExMWJMcXEx/P39MWHCBOTl5SEiIgJz585Fenq6GLNz507odDosX74c3333Hby8vKDValFWVmaaziAiakEWgiAI5k7CXAwGA5RKJSoqKqBQKFptP32Xprbatp/V5dX+5k6BqN1qyjnm+vXrcHBwQHZ2NsaNG4eKigr06tULycnJmDZtGgCgsLAQgwYNQk5ODkaPHo39+/fj5ZdfxtWrV+Ho6AgASExMRFRUFK5fvw6ZTIaoqCikpqYiPz9f3NeMGTNQXl6OtLQ0AIBarcbIkSOxceNGAEBdXR1cXV2xcOFCLF26tMWOkcyjLV97TIHXt/ajqecZ3qklIjKjiooKAIC9vT0AIDc3FzU1NfD19RVj3N3d0bt3b+Tk5AAAcnJy4OnpKRa0AKDVamEwGFBQUCDGPLyN+pj6bVRXVyM3N9coxtLSEr6+vmJMY6qqqmAwGIwWIqK2gEUtEZGZ1NXVISIiAi+++CKGDBkCANDr9ZDJZLCzszOKdXR0hF6vF2MeLmjr2+vbHhdjMBhw9+5d/PTTT6itrW00pn4bjYmNjYVSqRQXV1fX5h84EVErYFFLRGQmYWFhyM/Px44dO8ydSpNFR0ejoqJCXK5cuWLulIiIAADW5k6AiKgjCg8PR0pKCg4fPgwXFxdxvUqlQnV1NcrLy43u1paWlkKlUokxv5yloH52hIdjfjljQmlpKRQKBWxtbWFlZQUrK6tGY+q30Ri5XA65XN78AyYiamUsaomITEgQBCxcuBB79uxBVlYW3NzcjNp9fHzQqVMnZGZmIjAwEABQVFSEkpISaDQaAIBGo8Ff/vIXlJWVwcHBAQCQkZEBhUIBDw8PMWbfvn1G287IyBC3IZPJ4OPjg8zMTAQEBAB4MBwiMzMT4eHhrXb89HQ6+kNfRE3BopaIyITCwsKQnJyML774At26dRPHryqVStja2kKpVCIkJAQ6nQ729vZQKBRYuHAhNBoNRo8eDQDw8/ODh4cHZs2ahbi4OOj1eixbtgxhYWHiXdQFCxZg48aNWLJkCd566y0cPHgQu3btQmrqf4ojnU6H4OBgjBgxAqNGjcKGDRtQWVmJOXPmmL5jiIieEYtaIiIT2rx5MwBg/PjxRuu3bt2KN998EwCwfv16WFpaIjAwEFVVVdBqtdi0aZMYa2VlhZSUFISGhkKj0aBLly4IDg7GypUrxRg3NzekpqYiMjIS8fHxcHFxwZYtW6DVasWY6dOn4/r164iJiYFer4e3tzfS0tIaPDxGRCQFnKeW89SaOwWidqsjzOHaEY6xLWjL15G2ite39oPz1BIRERFRh8GiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSV6zitrNmzdj6NChUCgUUCgU0Gg02L9/v9h+7949hIWFoUePHujatSsCAwNRWlpqtI2SkhL4+/ujc+fOcHBwwOLFi3H//n2jmKysLAwfPhxyuRz9+/dHUlJSg1wSEhLQt29f2NjYQK1W48SJE805FCIiIiJqR6ybE+zi4oLVq1djwIABEAQB27Ztw9SpU3H69GkMHjwYkZGRSE1Nxe7du6FUKhEeHo7XXnsN3377LQCgtrYW/v7+UKlUOHr0KK5du4bZs2ejU6dO+Otf/woAKC4uhr+/PxYsWIDt27cjMzMTc+fOhZOTE7RaLQBg586d0Ol0SExMhFqtxoYNG6DValFUVAQHB4cW7iIiIiLqCPouTW32dy6v9m+FTOhpWAiCIDzLBuzt7bFmzRpMmzYNvXr1QnJyMqZNmwYAKCwsxKBBg5CTk4PRo0dj//79ePnll3H16lU4OjoCABITExEVFYXr169DJpMhKioKqampyM/PF/cxY8YMlJeXIy0tDQCgVqsxcuRIbNy4EQBQV1cHV1dXLFy4EEuXLm1y7gaDAUqlEhUVFVAoFM/SDY/1NL8kpsJfRqLWY6pzjDl1hGNsC9rydaSteprrG4vatqmp55mnHlNbW1uLHTt2oLKyEhqNBrm5uaipqYGvr68Y4+7ujt69eyMnJwcAkJOTA09PT7GgBQCtVguDwYCCggIx5uFt1MfUb6O6uhq5ublGMZaWlvD19RVjHqWqqgoGg8FoISIiIiLpa3ZRe/bsWXTt2hVyuRwLFizAnj174OHhAb1eD5lMBjs7O6N4R0dH6PV6AIBerzcqaOvb69seF2MwGHD37l389NNPqK2tbTSmfhuPEhsbC6VSKS6urq7NPXwiIiIiaoOaXdQOHDgQeXl5OH78OEJDQxEcHIxz5861Rm4tLjo6GhUVFeJy5coVc6dERERERC2gWQ+KAYBMJkP//v0BAD4+Pjh58iTi4+Mxffp0VFdXo7y83OhubWlpKVQqFQBApVI1mKWgfnaEh2N+OWNCaWkpFAoFbG1tYWVlBSsrq0Zj6rfxKHK5HHK5vLmHTERERERt3DPPU1tXV4eqqir4+PigU6dOyMzMFNuKiopQUlICjUYDANBoNDh79izKysrEmIyMDCgUCnh4eIgxD2+jPqZ+GzKZDD4+PkYxdXV1yMzMFGOIiIiIqGNp1p3a6OhoTJ48Gb1798bt27eRnJyMrKwspKenQ6lUIiQkBDqdDvb29lAoFFi4cCE0Gg1Gjx4NAPDz84OHhwdmzZqFuLg46PV6LFu2DGFhYeId1AULFmDjxo1YsmQJ3nrrLRw8eBC7du1Caup/nkjU6XQIDg7GiBEjMGrUKGzYsAGVlZWYM2dOC3YNEREREUlFs4rasrIyzJ49G9euXYNSqcTQoUORnp6OX//61wCA9evXw9LSEoGBgaiqqoJWq8WmTZvE71tZWSElJQWhoaHQaDTo0qULgoODsXLlSjHGzc0NqampiIyMRHx8PFxcXLBlyxZxjloAmD59Oq5fv46YmBjo9Xp4e3sjLS2twcNjRERERNQxPPM8tVLGeWo5vx5Ra+oIc7h2hGNsC9rydaSj43W09bX6PLVERERERG0Fi1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiMjEDh8+jFdeeQXOzs6wsLDA3r17jdrffPNNWFhYGC2TJk0yirl58yaCgoKgUChgZ2eHkJAQ3LlzxyjmzJkzGDt2LGxsbODq6oq4uLgGuezevRvu7u6wsbGBp6cn9u3b1+LHS0RkCixqiYhMrLKyEl5eXkhISHhkzKRJk3Dt2jVx+cc//mHUHhQUhIKCAmRkZCAlJQWHDx/G/PnzxXaDwQA/Pz/06dMHubm5WLNmDVasWIEPP/xQjDl69ChmzpyJkJAQnD59GgEBAQgICEB+fn7LHzQRUStr1mtyiYjo2U2ePBmTJ09+bIxcLodKpWq07fz580hLS8PJkycxYsQIAMAHH3yAKVOm4L333oOzszO2b9+O6upqfPLJJ5DJZBg8eDDy8vKwbt06sfiNj4/HpEmTsHjxYgDAqlWrkJGRgY0bNyIxMbHRfVdVVaGqqkr8bDAYmn38REStgXdqiYjaoKysLDg4OGDgwIEIDQ3FjRs3xLacnBzY2dmJBS0A+Pr6wtLSEsePHxdjxo0bB5lMJsZotVoUFRXh1q1bYoyvr6/RfrVaLXJych6ZV2xsLJRKpbi4urq2yPESET0rFrVERG3MpEmT8OmnnyIzMxN/+9vfkJ2djcmTJ6O2thYAoNfr4eDgYPQda2tr2NvbQ6/XizGOjo5GMfWfnxRT396Y6OhoVFRUiMuVK1ee7WCJiFoIhx8QEbUxM2bMEP/t6emJoUOH4rnnnkNWVhYmTpxoxsweDIuQy+VmzYGIqDG8U0tE1Mb169cPPXv2xMWLFwEAKpUKZWVlRjH379/HzZs3xXG4KpUKpaWlRjH1n58U86ixvEREbRmLWiKiNu7HH3/EjRs34OTkBADQaDQoLy9Hbm6uGHPw4EHU1dVBrVaLMYcPH0ZNTY0Yk5GRgYEDB6J79+5iTGZmptG+MjIyoNFoWvuQiIhaHItaIiITu3PnDvLy8pCXlwcAKC4uRl5eHkpKSnDnzh0sXrwYx44dw+XLl5GZmYmpU6eif//+0Gq1AIBBgwZh0qRJmDdvHk6cOIFvv/0W4eHhmDFjBpydnQEAb7zxBmQyGUJCQlBQUICdO3ciPj4eOp1OzOPtt99GWloa1q5di8LCQqxYsQKnTp1CeHi4yfuEiOhZsaglIjKxU6dOYdiwYRg2bBgAQKfTYdiwYYiJiYGVlRXOnDmDV199Fc8//zxCQkLg4+ODb775xmgs6/bt2+Hu7o6JEydiypQpGDNmjNEctEqlEgcOHEBxcTF8fHywaNEixMTEGM1l+8ILLyA5ORkffvghvLy88M9//hN79+7FkCFDTNcZREQthA+KERGZ2Pjx4yEIwiPb09PTn7gNe3t7JCcnPzZm6NCh+Oabbx4b8/rrr+P1119/4v6IiNo63qklIiIiIsljUUtEREREksfhBx1c36WpzYq/vNq/lTIhIiIienq8U0tEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeZz9gIiIyMSaO/MMET0Z79QSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPKaVdTGxsZi5MiR6NatGxwcHBAQEICioiKjmHv37iEsLAw9evRA165dERgYiNLSUqOYkpIS+Pv7o3PnznBwcMDixYtx//59o5isrCwMHz4ccrkc/fv3R1JSUoN8EhIS0LdvX9jY2ECtVuPEiRPNORwiIiIiaieaVdRmZ2cjLCwMx44dQ0ZGBmpqauDn54fKykoxJjIyEl999RV2796N7OxsXL16Fa+99prYXltbC39/f1RXV+Po0aPYtm0bkpKSEBMTI8YUFxfD398fEyZMQF5eHiIiIjB37lykp6eLMTt37oROp8Py5cvx3XffwcvLC1qtFmVlZc/SH0REREQkQRaCIAhP++Xr16/DwcEB2dnZGDduHCoqKtCrVy8kJydj2rRpAIDCwkIMGjQIOTk5GD16NPbv34+XX34ZV69ehaOjIwAgMTERUVFRuH79OmQyGaKiopCamor8/HxxXzNmzEB5eTnS0tIAAGq1GiNHjsTGjRsBAHV1dXB1dcXChQuxdOnSRvOtqqpCVVWV+NlgMMDV1RUVFRVQKBRP2w1P1J5eh3h5tb+5UyCSDIPBAKVS2ernGHPqCMfYGtrTdaGj43Wx9TX1PPNMY2orKioAAPb29gCA3Nxc1NTUwNfXV4xxd3dH7969kZOTAwDIycmBp6enWNACgFarhcFgQEFBgRjz8DbqY+q3UV1djdzcXKMYS0tL+Pr6ijGNiY2NhVKpFBdXV9dnOXwiIiIiaiOeuqitq6tDREQEXnzxRQwZMgQAoNfrIZPJYGdnZxTr6OgIvV4vxjxc0Na317c9LsZgMODu3bv46aefUFtb22hM/TYaEx0djYqKCnG5cuVK8w+ciIiIiNoc66f9YlhYGPLz83HkyJGWzKdVyeVyyOVyc6dBRERERC3sqe7UhoeHIyUlBYcOHYKLi4u4XqVSobq6GuXl5UbxpaWlUKlUYswvZ0Oo//ykGIVCAVtbW/Ts2RNWVlaNxtRvg4iIiIg6jmYVtYIgIDw8HHv27MHBgwfh5uZm1O7j44NOnTohMzNTXFdUVISSkhJoNBoAgEajwdmzZ41mKcjIyIBCoYCHh4cY8/A26mPqtyGTyeDj42MUU1dXh8zMTDGGiIiIiDqOZg0/CAsLQ3JyMr744gt069ZNHL+qVCpha2sLpVKJkJAQ6HQ62NvbQ6FQYOHChdBoNBg9ejQAwM/PDx4eHpg1axbi4uKg1+uxbNkyhIWFiUMDFixYgI0bN2LJkiV46623cPDgQezatQupqf95WlSn0yE4OBgjRozAqFGjsGHDBlRWVmLOnDkt1TdEREREJBHNKmo3b94MABg/frzR+q1bt+LNN98EAKxfvx6WlpYIDAxEVVUVtFotNm3aJMZaWVkhJSUFoaGh0Gg06NKlC4KDg7Fy5Uoxxs3NDampqYiMjER8fDxcXFywZcsWaLVaMWb69Om4fv06YmJioNfr4e3tjbS0tAYPjxERERFR+/dM89RKnanmV2xP8xFyPj6ipusIc7h2hGNsDe3putDR8brY+kwyTy0RETXf4cOH8corr8DZ2RkWFhbYu3evUbsgCIiJiYGTkxNsbW3h6+uLCxcuGMXcvHkTQUFBUCgUsLOzQ0hICO7cuWMUc+bMGYwdOxY2NjZwdXVFXFxcg1x2794Nd3d32NjYwNPTE/v27Wvx4yUiMgUWtUREJlZZWQkvLy8kJCQ02h4XF4f3338fiYmJOH78OLp06QKtVot79+6JMUFBQSgoKEBGRgZSUlJw+PBhzJ8/X2w3GAzw8/NDnz59kJubizVr1mDFihX48MMPxZijR49i5syZCAkJwenTpxEQEICAgACjtzkSEUkFhx9w+EGz8M8sRE3XlHOMhYUF9uzZg4CAAAAP7tI6Oztj0aJFeOeddwA8eHujo6MjkpKSMGPGDJw/fx4eHh44efIkRowYAQBIS0vDlClT8OOPP8LZ2RmbN2/GH//4R/GlOACwdOlS7N27F4WFhQAePJtQWVmJlJQUMZ/Ro0fD29sbiYmJLXaM1FB7ui50dLwutj4OPyAikqDi4mLo9Xqj14ArlUqo1Wqj143b2dmJBS0A+Pr6wtLSEsePHxdjxo0bJxa0wIPXjRcVFeHWrVtizONeSd6YqqoqGAwGo4WIqC1gUUtE1IbUT5X4uNeA6/V6ODg4GLVbW1vD3t6+RV5J/rjXjcfGxkKpVIqLq6trcw+RiKhVPPVrcjsq/smIiDqy6Oho6HQ68bPBYGBhS0RtAu/UEhG1IfWv+n7ca8BVKpXRWxkB4P79+7h582aLvJL8ca8bl8vlUCgURgsRUVvAopaIqA1xc3ODSqUyeg24wWDA8ePHjV43Xl5ejtzcXDHm4MGDqKurg1qtFmMOHz6MmpoaMSYjIwMDBw5E9+7dxZjHvZKciEhKWNQSEZnYnTt3kJeXh7y8PAAPHg7Ly8tDSUkJLCwsEBERgT//+c/48ssvcfbsWcyePRvOzs7iDAmDBg3CpEmTMG/ePJw4cQLffvstwsPDMWPGDDg7OwMA3njjDchkMoSEhKCgoAA7d+5EfHy80dCBt99+G2lpaVi7di0KCwuxYsUKnDp1CuHh4abuEiKiZ8YxtUREJnbq1ClMmDBB/FxfaAYHByMpKQlLlixBZWUl5s+fj/LycowZMwZpaWmwsbERv7N9+3aEh4dj4sSJ4qvJ33//fbFdqVTiwIEDCAsLg4+PD3r27ImYmBijuWxfeOEFJCcnY9myZfjDH/6AAQMGYO/evRgyZIgJeoGIqGVxntpmzq/Y0R8U43x8RE3XEeZw7QjH2Bo6+rWkPeF1sfVxnloiIiIi6jBY1BIRERGR5LGoJSIiIiLJ44Ni1CxPMw6M442IiIiotfFOLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyrM2dABEREZFU9V2a2uzvXF7t3wqZEO/UEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikrxmF7WHDx/GK6+8AmdnZ1hYWGDv3r1G7YIgICYmBk5OTrC1tYWvry8uXLhgFHPz5k0EBQVBoVDAzs4OISEhuHPnjlHMmTNnMHbsWNjY2MDV1RVxcXENctm9ezfc3d1hY2MDT09P7Nu3r7mHQ0RERETtQLOL2srKSnh5eSEhIaHR9ri4OLz//vtITEzE8ePH0aVLF2i1Wty7d0+MCQoKQkFBATIyMpCSkoLDhw9j/vz5YrvBYICfnx/69OmD3NxcrFmzBitWrMCHH34oxhw9ehQzZ85ESEgITp8+jYCAAAQEBCA/P7+5h0REREREEmchCILw1F+2sMCePXsQEBAA4MFdWmdnZyxatAjvvPMOAKCiogKOjo5ISkrCjBkzcP78eXh4eODkyZMYMWIEACAtLQ1TpkzBjz/+CGdnZ2zevBl//OMfodfrIZPJAABLly7F3r17UVhYCACYPn06KisrkZKSIuYzevRoeHt7IzExsUn5GwwGKJVKVFRUQKFQNOk7TzPJckfHSaapo3qac4zUdIRjbA28lnRsvC42T1PPMy06pra4uBh6vR6+vr7iOqVSCbVajZycHABATk4O7OzsxIIWAHx9fWFpaYnjx4+LMePGjRMLWgDQarUoKirCrVu3xJiH91MfU7+fxlRVVcFgMBgtRERERCR9LVrU6vV6AICjo6PRekdHR7FNr9fDwcHBqN3a2hr29vZGMY1t4+F9PCqmvr0xsbGxUCqV4uLq6trcQyQiIiKiNsja3AmYUnR0NHQ6nfjZYDCwsCUiomfCoQREbUOLFrUqlQoAUFpaCicnJ3F9aWkpvL29xZiysjKj792/fx83b94Uv69SqVBaWmoUU//5STH17Y2Ry+WQy+VPcWRERKazYsUKvPvuu0brBg4cKD5TcO/ePSxatAg7duxAVVUVtFotNm3aZPTXq5KSEoSGhuLQoUPo2rUrgoODERsbC2vr/5z2s7KyoNPpUFBQAFdXVyxbtgxvvvmmSY6RqCN7mv8R4jjcJ2vR4Qdubm5QqVTIzMwU1xkMBhw/fhwajQYAoNFoUF5ejtzcXDHm4MGDqKurg1qtFmMOHz6MmpoaMSYjIwMDBw5E9+7dxZiH91MfU78fIiIpGzx4MK5duyYuR44cEdsiIyPx1VdfYffu3cjOzsbVq1fx2muvie21tbXw9/dHdXU1jh49im3btiEpKQkxMTFiTHFxMfz9/TFhwgTk5eUhIiICc+fORXp6ukmPk4iopTT7Tu2dO3dw8eJF8XNxcTHy8vJgb2+P3r17IyIiAn/+858xYMAAuLm54U9/+hOcnZ3FGRIGDRqESZMmYd68eUhMTERNTQ3Cw8MxY8YMODs7AwDeeOMNvPvuuwgJCUFUVBTy8/MRHx+P9evXi/t9++238V//9V9Yu3Yt/P39sWPHDpw6dcpo2i8iIqmytrZu9C9PFRUV+Pjjj5GcnIyXXnoJALB161YMGjQIx44dw+jRo3HgwAGcO3cOX3/9NRwdHeHt7Y1Vq1YhKioKK1asgEwmQ2JiItzc3LB27VoAD87NR44cwfr166HVak16rERELaHZd2pPnTqFYcOGYdiwYQAAnU6HYcOGiXcAlixZgoULF2L+/PkYOXIk7ty5g7S0NNjY2Ijb2L59O9zd3TFx4kRMmTIFY8aMMSpGlUolDhw4gOLiYvj4+GDRokWIiYkxmsv2hRdeQHJyMj788EN4eXnhn//8J/bu3YshQ4Y8dWcQEbUVFy5cgLOzM/r164egoCCUlJQAAHJzc1FTU2M0+4u7uzt69+5tNMuMp6en0XAErVYLg8GAgoICMaa5M8gAnEWGiNquZt+pHT9+PB43ta2FhQVWrlyJlStXPjLG3t4eycnJj93P0KFD8c033zw25vXXX8frr7/++ISJiCRGrVYjKSkJAwcOxLVr1/Duu+9i7NixyM/PF+fvtrOzM/rOL2eZedoZZAwGA+7evQtbW9tGc4uNjW0w3peIqC3oULMfEBFJweTJk8V/Dx06FGq1Gn369MGuXbseWWyaCmeRIaK2qkUfFCMiopZnZ2eH559/HhcvXoRKpUJ1dTXKy8uNYh6e/eVZZpBRKBSPLZzlcjkUCoXRQkTUFrCoJSJq4+7cuYNLly7ByckJPj4+6NSpk9HsL0VFRSgpKTGaZebs2bNG0ydmZGRAoVDAw8NDjOEMMkTUnrCoJSJqY9555x1kZ2fj8uXLOHr0KH7zm9/AysoKM2fOhFKpREhICHQ6HQ4dOoTc3FzMmTMHGo0Go0ePBgD4+fnBw8MDs2bNwvfff4/09HQsW7YMYWFh4lzdCxYswA8//IAlS5agsLAQmzZtwq5duxAZGWnOQyciemocU0tE1Mb8+OOPmDlzJm7cuIFevXphzJgxOHbsGHr16gUAWL9+PSwtLREYGGj08oV6VlZWSElJQWhoKDQaDbp06YLg4GCjB3jd3NyQmpqKyMhIxMfHw8XFBVu2bOF0XkQkWRbC46YyaOcMBgOUSiUqKiqaPC6Mr0M0Db45hdqDpznHSE1HOMYn4XWBTKEjXxebep7h8AMiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5FmbOwGixvRdmtrs71xe7d8KmRAREZEU8E4tEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjy+KAYtRt8uIyIiKjj4p1aIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHk8UExIiIiojauuQ9Dd8QHoXmnloiIiIgkj3dqqUPjNGBERETtA+/UEhEREZHksaglIiIiIsnj8AMiIqL/8zRDkoiobWBRS0RE7RILVKKORfJFbUJCAtasWQO9Xg8vLy988MEHGDVqlLnTIiKSDHOcRzk9ERG1NEkXtTt37oROp0NiYiLUajU2bNgArVaLoqIiODg4mDs9IqI2TyrnUd51JaInsRAEQTB3Ek9LrVZj5MiR2LhxIwCgrq4Orq6uWLhwIZYuXdogvqqqClVVVeLniooK9O7dG1euXIFCoWjSPocsT2+Z5Emy8t/VmjsFkgiDwQBXV1eUl5dDqVSaO51GmeM8CvBcStQWtdXrW5PPpYJEVVVVCVZWVsKePXuM1s+ePVt49dVXG/3O8uXLBQBcuHDhYtLlypUrJjgrNh/Po1y4cJHS8qRzqWSHH/z000+ora2Fo6Oj0XpHR0cUFhY2+p3o6GjodDrxc11dHW7evIkePXrAwsJCXF//fwTNvfPQ3rAf2Af12A8PNLcfBEHA7du34ezsbILsmq81z6NtHX+mG8d+aYh90pCp+6Sp51LJFrVPQy6XQy6XG62zs7N7ZLxCoeAPMNgPAPugHvvhgeb0Q1sddvC0mnsebev4M9049ktD7JOGTNknTTmXSvblCz179oSVlRVKS0uN1peWlkKlUpkpKyIi6eB5lIjaE8kWtTKZDD4+PsjMzBTX1dXVITMzExqNxoyZERFJA8+jRNSeSHr4gU6nQ3BwMEaMGIFRo0Zhw4YNqKysxJw5c55pu3K5HMuXL2/wJ7aOhv3APqjHfnigPfZDa51H27r2+N+yJbBfGmKfNNRW+0TSU3oBwMaNG8VJw729vfH+++9DrVabOy0iIsngeZSI2gPJF7VERERERJIdU0tEREREVI9FLRERERFJHotaIiIiIpI8FrVEREREJHksan8hISEBffv2hY2NDdRqNU6cOGHulJpsxYoVsLCwMFrc3d3F9nv37iEsLAw9evRA165dERgY2GDS9ZKSEvj7+6Nz585wcHDA4sWLcf/+faOYrKwsDB8+HHK5HP3790dSUlKDXEzVj4cPH8Yrr7wCZ2dnWFhYYO/evUbtgiAgJiYGTk5OsLW1ha+vLy5cuGAUc/PmTQQFBUGhUMDOzg4hISG4c+eOUcyZM2cwduxY2NjYwNXVFXFxcQ1y2b17N9zd3WFjYwNPT0/s27ev2bm0Vj+8+eabDX42Jk2a1K76ITY2FiNHjkS3bt3g4OCAgIAAFBUVGcW0pd+BpuRCreP27duIiIhAnz59YGtrixdeeAEnT540d1om0xLnzfboSf3y+eefw8/PT3wldF5enlnyNKXH9UlNTQ2ioqLg6emJLl26wNnZGbNnz8bVq1fNl7BAoh07dggymUz45JNPhIKCAmHevHmCnZ2dUFpaau7UmmT58uXC4MGDhWvXronL9evXxfYFCxYIrq6uQmZmpnDq1Clh9OjRwgsvvCC2379/XxgyZIjg6+srnD59Wti3b5/Qs2dPITo6Woz54YcfhM6dOws6nU44d+6c8MEHHwhWVlZCWlqaGGPKfty3b5/wxz/+Ufj8888FAMKePXuM2levXi0olUph7969wvfffy+8+uqrgpubm3D37l0xZtKkSYKXl5dw7Ngx4ZtvvhH69+8vzJw5U2yvqKgQHB0dhaCgICE/P1/4xz/+Idja2gp///vfxZhvv/1WsLKyEuLi4oRz584Jy5YtEzp16iScPXu2Wbm0Vj8EBwcLkyZNMvrZuHnzplGM1PtBq9UKW7duFfLz84W8vDxhypQpQu/evYU7d+6IMW3pd+BJuVDr+e1vfyt4eHgI2dnZwoULF4Tly5cLCoVC+PHHH82dmkm0xHmzPXpSv3z66afCu+++K3z00UcCAOH06dNmydOUHtcn5eXlgq+vr7Bz506hsLBQyMnJEUaNGiX4+PiYLV8WtQ8ZNWqUEBYWJn6ura0VnJ2dhdjYWDNm1XTLly8XvLy8Gm0rLy8XOnXqJOzevVtcd/78eQGAkJOTIwjCgx9eS0tLQa/XizGbN28WFAqFUFVVJQiCICxZskQYPHiw0banT58uaLVa8bO5+vGXv3B1dXWCSqUS1qxZI64rLy8X5HK58I9//EMQBEE4d+6cAEA4efKkGLN//37BwsJC+Pe//y0IgiBs2rRJ6N69u9gHgiAIUVFRwsCBA8XPv/3tbwV/f3+jfNRqtfDf//3fTc6lpTyqqJ06deojv9Me+6GsrEwAIGRnZ4v7aSu/A03JhVrHzz//LFhZWQkpKSlG64cPHy788Y9/NFNW5vM0582OoLHzaL3i4uIOU9Q+7HF9Uu/EiRMCAOFf//qXaZL6BQ4/+D/V1dXIzc2Fr6+vuM7S0hK+vr7IyckxY2bNc+HCBTg7O6Nfv34ICgpCSUkJACA3Nxc1NTVGx+fu7o7evXuLx5eTkwNPT084OjqKMVqtFgaDAQUFBWLMw9uoj6nfRlvqx+LiYuj1eqNclEol1Gq10THb2dlhxIgRYoyvry8sLS1x/PhxMWbcuHGQyWRijFarRVFREW7duiXGPK5fmpJLa8vKyoKDgwMGDhyI0NBQ3LhxQ2xrj/1QUVEBALC3twfQtn4HmpILtY779++jtrYWNjY2RuttbW1x5MgRM2XVdrSFcxVJV0VFBSwsLGBnZ2eW/bOo/T8//fQTamtrjS5mAODo6Ai9Xm+mrJpHrVYjKSkJaWlp2Lx5M4qLizF27Fjcvn0ber0eMpmswQ/aw8en1+sbPf76tsfFGAwG3L17t031Y/3+HpeLXq+Hg4ODUbu1tTXs7e1bpF8ebn9SLq1p0qRJ+PTTT5GZmYm//e1vyM7OxuTJk1FbWyvm1576oa6uDhEREXjxxRcxZMgQcd9t5XegKblQ6+jWrRs0Gg1WrVqFq1evora2Fp999hlycnJw7do1c6dnduY+V5F03bt3D1FRUZg5cyYUCoVZcrA2y16pVUyePFn899ChQ6FWq9GnTx/s2rULtra2ZsyMzG3GjBnivz09PTF06FA899xzyMrKwsSJE82YWesICwtDfn4+77xRo/73f/8Xb731Fn71q1/BysoKw4cPx8yZM5Gbm2vu1IgkqaamBr/97W8hCAI2b95stjx4p/b/9OzZE1ZWVg2ePi4tLYVKpTJTVs/Gzs4Ozz//PC5evAiVSoXq6mqUl5cbxTx8fCqVqtHjr297XIxCoYCtrW2b6sf6/T0uF5VKhbKyMqP2+/fv4+bNmy3SLw+3PykXU+rXrx969uyJixcvivm1l34IDw9HSkoKDh06BBcXF3F9W/odaEou1Hqee+45ZGdn486dO7hy5QpOnDiBmpoa9OvXz9ypmV1bO1dR21df0P7rX/9CRkaG2e7SAixqRTKZDD4+PsjMzBTX1dXVITMzExqNxoyZPb07d+7g0qVLcHJygo+PDzp16mR0fEVFRSgpKRGPT6PR4OzZs0bFTf0PqIeHhxjz8DbqY+q30Zb60c3NDSqVyigXg8GA48ePGx1zeXm50R2agwcPoq6uDmq1Wow5fPgwampqxJiMjAwMHDgQ3bt3F2Me1y9NycWUfvzxR9y4cQNOTk4A2kc/CIKA8PBw7NmzBwcPHoSbm5tRe1v6HWhKLtT6unTpAicnJ9y6dQvp6emYOnWquVMyu7Z2rqK2rb6gvXDhAr7++mv06NHDvAmZ5fG0NmrHjh2CXC4XkpKShHPnzgnz588X7OzsjJ6EbssWLVokZGVlCcXFxcK3334r+Pr6Cj179hTKysoEQXgwhVDv3r2FgwcPCqdOnRI0Go2g0WjE79dPZ+Tn5yfk5eUJaWlpQq9evRqdzmjx4sXC+fPnhYSEhEanMzJVP96+fVs4ffq0cPr0aQGAsG7dOuH06dPik5erV68W7OzshC+++EI4c+aMMHXq1Ean9Bo2bJhw/Phx4ciRI8KAAQOMprIqLy8XHB0dhVmzZgn5+fnCjh07hM6dOzeYysra2lp47733hPPnzwvLly9vdCqrJ+XSGv1w+/Zt4Z133hFycnKE4uJi4euvvxaGDx8uDBgwQLh371676YfQ0FBBqVQKWVlZRlOX/fzzz2JMW/odeFIu1HrS0tKE/fv3Cz/88INw4MABwcvLS1Cr1UJ1dbW5UzOJljhvtkdP6pcbN24Ip0+fFlJTUwUAwo4dO4TTp08L165dM3PmredxfVJdXS28+uqrgouLi5CXl2d03n14lhxTYlH7Cx988IHQu3dvQSaTCaNGjRKOHTtm7pSabPr06YKTk5Mgk8mEX/3qV8L06dOFixcviu13794V/ud//kfo3r270LlzZ+E3v/lNg1/Gy5cvC5MnTxZsbW2Fnj17CosWLRJqamqMYg4dOiR4e3sLMplM6Nevn7B169YGuZiqHw8dOiQAaLAEBwcLgvBgepo//elPgqOjoyCXy4WJEycKRUVFRtu4ceOGMHPmTKFr166CQqEQ5syZI9y+fdso5vvvvxfGjBkjyOVy4Ve/+pWwevXqBrns2rVLeP755wWZTCYMHjxYSE1NNWpvSi6t0Q8///yz4OfnJ/Tq1Uvo1KmT0KdPH2HevHkN/idD6v3Q2PEDMPr5bEu/A03JhVrHzp07hX79+gkymUxQqVRCWFiYUF5ebu60TKYlzpvt0ZP6ZevWrY22L1++3Kx5t6bH9Un91GaNLYcOHTJLvhaCIAgtf/+XiIiIiMh0OKaWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpK8/w/cR3oLjPe3cgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcrNCRjaYmfl"
   },
   "source": [
    "Our task is to predict one number, __Log1pSalary__.\n",
    "\n",
    "To do so, our model can access a number of features:\n",
    "* Free text: __`Title`__ and  __`FullDescription`__\n",
    "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "5AlwDyvoYmfl",
    "outputId": "70503575-b6c1-47d9-e87f-1e104d486269"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131498</th>\n",
       "      <td>70192076</td>\n",
       "      <td>Smarter Choices Coordinator</td>\n",
       "      <td>Job Purpose: To encourage more people to take ...</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>full_time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>European Solution Limited</td>\n",
       "      <td>Other/General Jobs</td>\n",
       "      <td>32.16 per hour</td>\n",
       "      <td>61747</td>\n",
       "      <td>Jobcentre Plus</td>\n",
       "      <td>11.030817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157952</th>\n",
       "      <td>71125531</td>\n",
       "      <td>Supply Chain Planner</td>\n",
       "      <td>Supply Chain Planner Farnborough Up to ****  p...</td>\n",
       "      <td>Farnborough, Hampshire</td>\n",
       "      <td>Farnborough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Orion Electrotech</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0 - 50000/annum pension, bonus</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.126671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233272</th>\n",
       "      <td>72480707</td>\n",
       "      <td>Senior Support Engineer/ 3rd Line Support Engi...</td>\n",
       "      <td>My client is a market leading Security organis...</td>\n",
       "      <td>Shipley</td>\n",
       "      <td>Shipley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>TEKsystems</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>22k - 30k pa + bonus, overtime, on call</td>\n",
       "      <td>26000</td>\n",
       "      <td>jobsite.co.uk</td>\n",
       "      <td>10.165891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                              Title  \\\n",
       "131498  70192076                        Smarter Choices Coordinator   \n",
       "157952  71125531                               Supply Chain Planner   \n",
       "233272  72480707  Senior Support Engineer/ 3rd Line Support Engi...   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "131498  Job Purpose: To encourage more people to take ...   \n",
       "157952  Supply Chain Planner Farnborough Up to ****  p...   \n",
       "233272  My client is a market leading Security organis...   \n",
       "\n",
       "                   LocationRaw LocationNormalized ContractType ContractTime  \\\n",
       "131498                Coventry           Coventry    full_time          NaN   \n",
       "157952  Farnborough, Hampshire        Farnborough          NaN    permanent   \n",
       "233272                 Shipley            Shipley          NaN    permanent   \n",
       "\n",
       "                          Company            Category  \\\n",
       "131498  European Solution Limited  Other/General Jobs   \n",
       "157952          Orion Electrotech    Engineering Jobs   \n",
       "233272                 TEKsystems             IT Jobs   \n",
       "\n",
       "                                      SalaryRaw  SalaryNormalized  \\\n",
       "131498                           32.16 per hour             61747   \n",
       "157952           0 - 50000/annum pension, bonus             25000   \n",
       "233272  22k - 30k pa + bonus, overtime, on call             26000   \n",
       "\n",
       "              SourceName  Log1pSalary  \n",
       "131498    Jobcentre Plus    11.030817  \n",
       "157952  cv-library.co.uk    10.126671  \n",
       "233272     jobsite.co.uk    10.165891  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "TARGET_COLUMN = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8QGTxpZYmfl"
   },
   "source": [
    "### Preprocessing text data\n",
    "\n",
    "We begins with tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
    "\n",
    "__Your task__ is to lowercase and tokenize all `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for future processing.\n",
    "\n",
    "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tL-JsrLEYmfl",
    "outputId": "f6cabea9-c79a-44b8-d028-d455224926a7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      "2         Mathematical Modeller / Simulation Analyst / O...\n",
      "100002    A successful and high achieving specialist sch...\n",
      "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "ZlsdYbbSYmfl"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#TODO\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "data[\"FullDescription\"] = data[\"FullDescription\"].apply(lambda x: ' '.join(tokenizer.tokenize(str(x).lower())))\n",
    "data[\"Title\"] = data[\"Title\"].apply(lambda x: ' '.join(tokenizer.tokenize(str(x).lower())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nDdt15kYmfl"
   },
   "source": [
    "Now we can assume that our text is a space-separated list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EnqrsZlYmfl",
    "outputId": "abfea7a5-c73a-4435-b0ba-b756b0955948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeVfzYKnYmfl"
   },
   "source": [
    "Not all words are equally useful. Some may be typos or rare words that appear only a few times.\n",
    "\n",
    "To address this, we will count the occurrences of each word in the data to create a \"whitelist\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpRd_5Nj8iS9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Engineering Jobs'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Title'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "h52xhiw8Ymfl"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "for text in data[\"Title\"].values:\n",
    "    token_counts.update(text.split())\n",
    "for text in data[\"FullDescription\"].values:\n",
    "    token_counts.update(text.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "WHAqK8OvYmfl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4H8lNPLt_V61"
   },
   "source": [
    "The word distribution fallows so called [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "bHUB4RK1-FxP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 2657388),\n",
       " ('.', 2523216),\n",
       " (',', 2318606),\n",
       " ('the', 2080994),\n",
       " ('to', 2019884),\n",
       " ('a', 1521925),\n",
       " ('of', 1426213),\n",
       " ('in', 1035792),\n",
       " ('for', 867233),\n",
       " ('with', 728884),\n",
       " ('you', 694177),\n",
       " ('****', 681869),\n",
       " ('will', 652403),\n",
       " ('be', 625163),\n",
       " ('is', 599665),\n",
       " ('/', 554003),\n",
       " ('this', 497002),\n",
       " ('as', 472859),\n",
       " ('an', 442713),\n",
       " ('experience', 429019),\n",
       " ('are', 428534),\n",
       " (':', 415648),\n",
       " ('on', 394777),\n",
       " ('have', 361514),\n",
       " ('or', 329512),\n",
       " ('role', 292680),\n",
       " ('work', 280280),\n",
       " ('business', 275975),\n",
       " ('your', 275371),\n",
       " ('team', 271843),\n",
       " ('we', 238825),\n",
       " ('skills', 236248),\n",
       " ('manager', 235225),\n",
       " ('(', 234419),\n",
       " ('sales', 229086),\n",
       " ('our', 223441),\n",
       " ('working', 222783),\n",
       " ('within', 217418),\n",
       " ('all', 216046),\n",
       " ('that', 200655),\n",
       " ('client', 198691),\n",
       " ('management', 190344),\n",
       " (')', 185958),\n",
       " ('their', 185011),\n",
       " ('company', 177583),\n",
       " ('at', 171875),\n",
       " ('please', 171870),\n",
       " ('development', 168938),\n",
       " ('uk', 163958),\n",
       " ('from', 162263),\n",
       " ('support', 161650),\n",
       " ('job', 156315),\n",
       " ('looking', 155766),\n",
       " ('s', 151120),\n",
       " ('service', 145467),\n",
       " ('excellent', 144946),\n",
       " ('required', 137902),\n",
       " ('opportunity', 131569),\n",
       " ('new', 129924),\n",
       " ('if', 127675),\n",
       " ('must', 125095),\n",
       " (\"'\", 123716),\n",
       " ('recruitment', 123310),\n",
       " ('who', 117642),\n",
       " ('it', 117555),\n",
       " ('successful', 116666),\n",
       " ('by', 116464),\n",
       " ('customer', 115173),\n",
       " ('knowledge', 113417),\n",
       " ('apply', 113066),\n",
       " ('based', 108473),\n",
       " ('services', 108393),\n",
       " ('ability', 103776),\n",
       " ('they', 103373),\n",
       " ('project', 102963),\n",
       " ('strong', 100515),\n",
       " (';', 99508),\n",
       " ('ensure', 97374),\n",
       " ('candidate', 96280),\n",
       " ('design', 96089),\n",
       " ('high', 95158),\n",
       " ('engineer', 94623),\n",
       " ('care', 94612),\n",
       " ('join', 94014),\n",
       " ('salary', 93465),\n",
       " ('environment', 92623),\n",
       " ('training', 92149),\n",
       " ('technical', 91480),\n",
       " ('leading', 90732),\n",
       " ('good', 90594),\n",
       " ('has', 90339),\n",
       " ('including', 90178),\n",
       " ('not', 89962),\n",
       " ('clients', 89241),\n",
       " ('able', 88710),\n",
       " ('also', 88122),\n",
       " ('com', 87759),\n",
       " ('www', 87603),\n",
       " ('senior', 87513),\n",
       " ('cv', 87495)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "psRR4ugVYmfl"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Word counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "3Xf4Bxgq_et1"
   },
   "outputs": [],
   "source": [
    "# len([token for token, count in token_counts.items() if count > 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKLpdPIfYmfl"
   },
   "source": [
    "__Task 1.1__ Get a list of all tokens that occur at least 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "0NVuyjGYYmfm"
   },
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "kkTuCrDGYmfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size:\", len(tokens))\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u92jzpXvYmfm"
   },
   "source": [
    "__Task 1.2__ Build the inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "ONJz25HNYmfm"
   },
   "outputs": [],
   "source": [
    "token_to_id =  {token: idx for idx, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "JXwarpLoYmfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDoPFQ3KYmfm"
   },
   "source": [
    "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "3Ky5dsQ2Ymfm"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "\n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "\n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "OKn9kGS3Ymfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[   2    3    4    1    1]\n",
      " [ 998  176    1    1    1]\n",
      " [  18 3472  242   59    6]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DQ16SCyYmfm"
   },
   "source": [
    "Now, let's  encode the categirical data we have.\n",
    "\n",
    "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "zwPztIb-Ymfm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DictVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.DictVectorizer.html\">?<span>Documentation for DictVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmI8noCuYmfm"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to cast our data into numbers, we can design a machine learning experiment.\n",
    "\n",
    "We won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and building the vocabulary. A more strict way would be to do that on training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "5jLQedLVYmfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "1bjEgojNYmfm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def to_tensors(batch, device):\n",
    "    batch_tensors = dict()\n",
    "    for key, arr in batch.items():\n",
    "        if key in [\"FullDescription\", \"Title\"]:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device, dtype=torch.int64)\n",
    "        else:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device)\n",
    "    return batch_tensors\n",
    "\n",
    "\n",
    "def make_batch(data, max_len=None, word_dropout=0, device=device):\n",
    "    \"\"\"\n",
    "    Creates a torch-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1)) #.sum(axis=1) #.argmax(axis=1)\n",
    "    batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
    "\n",
    "    if word_dropout != 0:\n",
    "        batch[\"Title\"] = apply_word_dropout(batch[\"Title\"], 1. - word_dropout)\n",
    "\n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "\n",
    "    if TARGET_COLUMN in data.columns:\n",
    "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
    "\n",
    "    return to_tensors(batch, device)\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLfI8RvkYmfm",
    "outputId": "8f95734c-7739-4bb9-d01e-e8744d8387ea",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': tensor([[   18,   287,   359,     1,     1,     1,     1],\n",
       "         [ 2863,    11,    12,    13,    55,    37, 12109],\n",
       "         [ 2833,   618,   858,    63,  7104,  7105,    64]], device='cuda:0'),\n",
       " 'FullDescription': tensor([[   18,   287,   359,  1408,   561,    18,   287,   359,  1464,  1408],\n",
       "         [ 2863,    11,    12,    13,    55,    37, 12109,  1767,  1166,    74],\n",
       "         [  142,  1617,  8830,  1314,  1464,   559,   560,   561,   618,   858]],\n",
       "        device='cuda:0'),\n",
       " 'Categorical': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'),\n",
       " 'Log1pSalary': tensor([ 9.7115, 10.4631, 10.7144], device='cuda:0')}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rd5jCiGYmfm"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our basic model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "![scheme](https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64, embed_size=64):\n",
    "        \"\"\" a simple sequential encoder for titles \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(n_tokens, embed_size)\n",
    "        self.conv = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        :param X: int64 (n_samples, n_tokens) matrix of token indices\n",
    "        :returns: float32 (n_samples, out_size) matrix of sentence vectors\n",
    "        \"\"\"\n",
    "        h = self.emb(X).transpose(1, 2)\n",
    "        h = self.relu(self.conv(h))\n",
    "        return self.pool(h).squeeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = TextEncoder()\n",
    "enc.to(device)\n",
    "enc(make_batch(data_train[:3], max_len=10)[\"Title\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJx1SGQzYmfm"
   },
   "outputs": [],
   "source": [
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=100):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.title_encoder = TextEncoder(n_tokens, out_size=hid_size, embed_size=hid_size) # during the lecture practice, Prof only used the title_encoder, but the graph said to also have a description encoder \n",
    "        self.description_encoder = TextEncoder(n_tokens, out_size=hid_size, embed_size=hid_size)\n",
    "        self.cat_encoder = nn.Linear(n_cat_features, hid_size) # added the categorical encoder to the model which was not added in the lecture\n",
    "        self.fc = nn.Linear(hid_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.title_encoder(batch[\"Title\"])).squeeze()+self.fc(self.description_encoder(batch[\"FullDescription\"]).squeeze()+self.fc(self.cat_encoder(batch[\"Categorical\"]).squeeze())).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "e07rYiBXYmfm"
   },
   "outputs": [],
   "source": [
    "model = SalaryPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "ZEAOQ1jHYmfm"
   },
   "outputs": [],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "batch = make_batch(data_train[:100], device=device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dummy_pred = model(batch)\n",
    "dummy_loss = criterion(dummy_pred, batch[TARGET_COLUMN])\n",
    "assert dummy_pred.shape == torch.Size([100])\n",
    "assert len(torch.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert dummy_loss.ndim == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIHN3eLsYmfm"
   },
   "source": [
    "#### Training and evaluation\n",
    "\n",
    "As usual, we gonna feed our monster with random minibatches of data.\n",
    "\n",
    "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "_JpQ4gQYYmfn"
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, device=device, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], device=device, **kwargs)\n",
    "            yield batch\n",
    "\n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlGBvUOSYmfn"
   },
   "source": [
    "### Model training\n",
    "\n",
    "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "99MLd9AsYmfn"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "K5jxfWuZYmfn"
   },
   "outputs": [],
   "source": [
    "def print_metrics(model, data, batch_size=BATCH_SIZE, name=\"\", device=torch.device('cpu'), **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterate_minibatches(data, batch_size=batch_size, shuffle=False, device=device, **kw):\n",
    "            batch_pred = model(batch)\n",
    "            squared_error += torch.sum(torch.square(batch_pred - batch[TARGET_COLUMN]))\n",
    "            abs_error += torch.sum(torch.abs(batch_pred - batch[TARGET_COLUMN]))\n",
    "            num_samples += len(batch_pred)\n",
    "    mse = squared_error.detach().cpu().numpy() / num_samples\n",
    "    mae = abs_error.detach().cpu().numpy() / num_samples\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % mse)\n",
    "    print(\"Mean absolute error: %.5f\" % mae)\n",
    "    return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710,
     "referenced_widgets": [
      "07bf9c7fe1f4431098997cc7fa1a7c92",
      "f9ae53a2b2714fdbb8b03a75e470d702",
      "36ce70f9f0b9422181b00e391c71fb87",
      "f7acd5693d824bfdaa2118f3695ab9a9",
      "2258576006254a24a7fd12625b8134b0",
      "b2dbb3fd673346b2b8489a2b11446745",
      "50840c75126a42db8137d083e03dbb5c",
      "8c19ed6fca1540a8b269fe1120902736",
      "982f9d4adbc6430f95c280beea6e1a20",
      "a2902d053080478b82c7b4f7eb9195e1",
      "608b9441525b48fbaedfedba55aa392c",
      "63ffb20d56c24910a0c22f021831d8e4",
      "0a1dd2f13bb347af9943bb9d2e8defa0",
      "d97af5fd168846fb8c9f21d4ff5bebce",
      "bd4231ce5c5c4c1086fb69ecdd716348",
      "f6a30814f1f2425da67e3135e993aa8a",
      "002e6a05cccf4b75b67564c9dde9acc6",
      "a4725d892023410ba0eccfc7422b8589",
      "1a46d9d0c1e846f9b9be0639f0a8bdc0",
      "6224403a65da420c909c527dbdcd6f76",
      "e1c33b713ba745aaba902f3f59928ba4",
      "4ede4f9569704369b71bbec4535d56f0",
      "d3950bf20ad34e1bae4357fe76487c9d",
      "ee94526e72e749d2b0475f2be6803ceb",
      "ed17fe5250f7444f9e5c724b454c5011",
      "07da6a0467e34232a938ffd368992f91",
      "4f604b78cea34114a2f5e60b87b30a51",
      "f410787f3b264c67a70a167df2c70e20",
      "dec4444d3d354e3abf76d10d25fb14ff",
      "cabc6658d39846b389b3f434cd1213ab",
      "6c975f5e9ba148fe878d7780855a372a",
      "874af4a3d028453e988ab7901b1559ff",
      "bae5a5a2f45e495ab435106703275e03",
      "8a5ab0322f574c3387f8340dbebb1e43",
      "ce0b75adbf0f4722a56a4955ee8f17e7",
      "f26a5a04c6464ed89551143ab901385b",
      "fb1316f2e5ca440c804d6ef54f19c5a1",
      "7227ed89cdb14f5ca2333e45cc369d3d",
      "6a2d7353590a416c81d1e125314ff8e7",
      "cc29c27860f94bb381b7223314ced3f0",
      "44679b989f82453c82485e35474a3f96",
      "5aa5ad1051694ceb939190dabb97cb84",
      "7f595c96662b4b18a7f84630f3217a6f",
      "1a57b88984df4542901af43d9c89cfa5"
     ]
    },
    "id": "5rlU4DvkYmfn",
    "outputId": "c0c2b53a-13cd-4ba4-9542-97194ac97a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:40, 76.44it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.12522\n",
      "Mean absolute error: 0.26928\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:27, 83.24it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.11249\n",
      "Mean absolute error: 0.25808\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:21, 86.58it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.09960\n",
      "Mean absolute error: 0.23848\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:19, 87.72it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.09276\n",
      "Mean absolute error: 0.23115\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:30, 81.16it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.09815\n",
      "Mean absolute error: 0.24134\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:25, 84.12it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.09723\n",
      "Mean absolute error: 0.23677\n",
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 199/12238 [00:03<03:06, 64.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[195], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m      9\u001b[0m         iterate_minibatches(data_train, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, device\u001b[38;5;241m=\u001b[39mdevice)),\n\u001b[1;32m     10\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_train) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m BATCH_SIZE\n\u001b[1;32m     11\u001b[0m     ):\n\u001b[1;32m     12\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, batch[TARGET_COLUMN])\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[146], line 9\u001b[0m, in \u001b[0;36miterate_minibatches\u001b[0;34m(data, batch_size, shuffle, cycle, device, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(indices)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(indices), batch_size):\n\u001b[0;32m----> 9\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mmake_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cycle: \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[139], line 28\u001b[0m, in \u001b[0;36mmake_batch\u001b[0;34m(data, max_len, word_dropout, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m as_matrix(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, max_len)\n\u001b[1;32m     27\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFullDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m as_matrix(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFullDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, max_len)\n\u001b[0;32m---> 28\u001b[0m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategorical\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m categorical_vectorizer\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#.sum(axis=1) #.argmax(axis=1)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m batch[TARGET_COLUMN] \u001b[38;5;241m=\u001b[39m data[TARGET_COLUMN]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m word_dropout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1068\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m-> 1068\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1107\u001b[0m, in \u001b[0;36mFrameApply.wrap_results\u001b[0;34m(self, results, res_index)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;66;03m# see if we can infer the results\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;129;01mand\u001b[39;00m is_sequence(results[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_results_for_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;66;03m# dict of scalars\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# the default dtype of an empty Series is `object`, but this\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# code can be hit by df.mean() where the result should have dtype\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# float64 even if it's an empty Series.\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m constructor_sliced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_constructor_sliced\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1349\u001b[0m, in \u001b[0;36mFrameColumnApply.wrap_results_for_axis\u001b[0;34m(self, results, res_index)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m# we have a non-series and don't want inference\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m-> 1349\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_sliced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m res_index\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;66;03m# we may want to infer results\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/series.py:537\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    535\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[0;32m--> 537\u001b[0m     data, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    539\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/series.py:651\u001b[0m, in \u001b[0;36mSeries._init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    648\u001b[0m     keys, values \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;241m0\u001b[39m), []\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Input is now list-like, so rely on \"standard\" construction:\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# Now we just make sure the order is respected, if any\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/series.py:490\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    487\u001b[0m name \u001b[38;5;241m=\u001b[39m ibase\u001b[38;5;241m.\u001b[39mmaybe_extract_name(name, data, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dtype(dtype)\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:7649\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   7648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:577\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    574\u001b[0m klass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype_to_subclass(arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    576\u001b[0m arr \u001b[38;5;241m=\u001b[39m klass\u001b[38;5;241m.\u001b[39m_ensure_array(arr, arr\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 577\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simple_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_pandas_object \u001b[38;5;129;01mand\u001b[39;00m data_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m data_dtype:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=device)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print_metrics(model, data_val, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpWt2n8gpXWm"
   },
   "source": [
    "# Homework (8 points)\n",
    "\n",
    "Your main task is to use some of the tricks you've learned about NN and analyze if you can improve __validation MAE__. Try __at least 2 options__ from the list below for a passing grade. Write a short report about what you have tried. More ideas = more bonus points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfRaEFpcqUrR"
   },
   "source": [
    "## Recommended options\n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `nn.BatchNorm*`/`L.BatchNormalization`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to perform pooling:\n",
    "* Max over time (independently for each feature)\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)},$$\n",
    "where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a dense layer.\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
    "\n",
    "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/). Or use pure tensorflow, it might even be easier :)\n",
    "\n",
    "#### C) Fun with words\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not download pre-trained embeddings from [here](http://nlp.stanford.edu/data/glove.6B.zip) and follow this [manual](https://keras.io/examples/nlp/pretrained_word_embeddings/) to initialize your Keras embedding layer with downloaded weights.\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left\n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping.\n",
    "* Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
    "* Plotting learning curves is usually a good idea\n",
    "  \n",
    "Good luck! And may the force be with you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64, embed_size=128): # Greater embed size than original\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(n_tokens, embed_size)\n",
    "        \n",
    "        # Triple the number of convolutions and add batch normalization to CNN architecture\n",
    "        self.conv1 = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(out_size)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(out_size)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(out_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3) # Add dropout to CNN architecture\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.emb(X).transpose(1, 2)\n",
    "        \n",
    "        h1 = self.relu(self.bn1(self.conv1(h)))\n",
    "        h2 = self.relu(self.bn2(self.conv2(h)))\n",
    "        h3 = self.relu(self.bn3(self.conv3(h)))\n",
    "\n",
    "        return self.pool(self.dropout(h1 + h2 + h3)).squeeze()\n",
    "\n",
    "\n",
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=100):\n",
    "        super().__init__()\n",
    "        self.title_encoder = ConvEncoder(n_tokens, out_size=hid_size, embed_size=hid_size) # during the lecture practice, Prof only used the title_encoder, but the graph said to also have a description encoder \n",
    "        self.description_encoder = ConvEncoder(n_tokens, out_size=hid_size, embed_size=hid_size)\n",
    "        self.fc = nn.Linear(hid_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.title_encoder(batch[\"Title\"])).squeeze()+self.fc(self.description_encoder(batch[\"FullDescription\"]).squeeze()).squeeze()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "batch = make_batch(data_train[:100], device=device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dummy_pred = model(batch)\n",
    "dummy_loss = criterion(dummy_pred, batch[TARGET_COLUMN])\n",
    "assert dummy_pred.shape == torch.Size([100])\n",
    "assert len(torch.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert dummy_loss.ndim == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cf7b96b1434dd8b1dfb9667306f3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: nan\n",
      "Mean absolute error: nan\n",
      "epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47211720bfa44809bab4b8372a3e5d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: nan\n",
      "Mean absolute error: nan\n",
      "epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d373a7df21574794a0063789a4c75006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: nan\n",
      "Mean absolute error: nan\n",
      "epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72aa498ffd884ee3b0f1faf91cc987bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: nan\n",
      "Mean absolute error: nan\n",
      "epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032bad1ea2214eb3b14d3b5f21b49502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: nan\n",
      "Mean absolute error: nan\n"
     ]
    }
   ],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=device)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print_metrics(model, data_val, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64, embed_size=128): # Greater embed size than original\n",
    "        super().__init__()\n",
    "        \n",
    "        # Implement initial single-convolution layer of CNN architecture\n",
    "        self.emb = nn.Embedding(n_tokens, embed_size)\n",
    "        self.conv = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Add attention layer to CNN architecture\n",
    "        self.attn = nn.Linear(out_size, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.emb(X).transpose(1, 2)\n",
    "        h = self.relu(self.conv(h))\n",
    "\n",
    "        # Compute attention weights and apply them to the output of the convolutional layer\n",
    "        attn_scores = self.attn(h.transpose(1, 2)).squeeze(2)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "\n",
    "        return torch.bmm(attn_weights.unsqueeze(1), h.transpose(1, 2)).squeeze(1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=100):\n",
    "        super().__init__()\n",
    "        self.title_encoder = AttnEncoder(n_tokens, out_size=hid_size, embed_size=hid_size) # during the lecture practice, Prof only used the title_encoder, but the graph said to also have a description encoder \n",
    "        self.description_encoder = AttnEncoder(n_tokens, out_size=hid_size, embed_size=hid_size)\n",
    "        self.fc = nn.Linear(hid_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.title_encoder(batch[\"Title\"])).squeeze()+self.fc(self.description_encoder(batch[\"FullDescription\"]).squeeze()).squeeze()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "batch = make_batch(data_train[:100], device=device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dummy_pred = model(batch)\n",
    "dummy_loss = criterion(dummy_pred, batch[TARGET_COLUMN])\n",
    "assert dummy_pred.shape == torch.Size([100])\n",
    "assert len(torch.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert dummy_loss.ndim == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20063f10cc1446db91219b3f6965ea36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.17193\n",
      "Mean absolute error: 0.32698\n",
      "epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ba7b334066411abf1c2e13ea7cef67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.13685\n",
      "Mean absolute error: 0.28510\n",
      "epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1eb692daac4d72a36bf0d1939efb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.11833\n",
      "Mean absolute error: 0.25951\n",
      "epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a979ff4ed5444c73844fcb859b0d03fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.10936\n",
      "Mean absolute error: 0.25001\n",
      "epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3bed115b614cc0bbae0de4d8bfb417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.10580\n",
      "Mean absolute error: 0.24436\n"
     ]
    }
   ],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=device)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print_metrics(model, data_val, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=100):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.title_encoder = TextEncoder(n_tokens, out_size=hid_size, embed_size=hid_size) # during the lecture practice, Prof only used the title_encoder, but the graph said to also have a description encoder \n",
    "        self.description_encoder = TextEncoder(n_tokens, out_size=hid_size, embed_size=hid_size)\n",
    "        self.fc = nn.Linear(hid_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.title_encoder(batch[\"Title\"])).squeeze()+self.fc(self.description_encoder(batch[\"FullDescription\"]).squeeze()).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4151c86dea8049c8abbe3a75847d11d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.13781\n",
      "Mean absolute error: 0.28252\n",
      "epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac803b85fbc4480a98d31a0d54dd214a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.15270\n",
      "Mean absolute error: 0.31154\n",
      "epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1278e6ba0b0247559066480d3470e45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.09564\n",
      "Mean absolute error: 0.23751\n",
      "epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfabdae739c9418180ad6311aacc157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08325\n",
      "Mean absolute error: 0.21687\n",
      "epoch: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744fa17186944ddb9ea8ee97e8527917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08409\n",
      "Mean absolute error: 0.21708\n",
      "epoch: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e27f6f7435494e83624bb55a267c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08694\n",
      "Mean absolute error: 0.22369\n",
      "epoch: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff74f89f842412aa32fb724a92badc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08979\n",
      "Mean absolute error: 0.22929\n",
      "epoch: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267f372a81594e0f8ce2a70c9033b455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08658\n",
      "Mean absolute error: 0.22376\n",
      "epoch: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173883bc7c0041fe9061a2deb619e5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08428\n",
      "Mean absolute error: 0.21806\n",
      "epoch: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e845853502404b956b26d9f217429f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08634\n",
      "Mean absolute error: 0.22140\n",
      "epoch: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e070b73b5048f4bd3fa41984f51ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.07811\n",
      "Mean absolute error: 0.20854\n",
      "epoch: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e47843ce80a4e1aaffaac7925f51212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.09262\n",
      "Mean absolute error: 0.23407\n",
      "epoch: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b62366a6b4b4e1b9087e5fc7cc16954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.07716\n",
      "Mean absolute error: 0.20734\n",
      "epoch: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeda8c9a7bcd4f38ba8dd9bdbf7635b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.07963\n",
      "Mean absolute error: 0.21113\n",
      "epoch: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570749dc3d7443e5a782888215fb0eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08465\n",
      "Mean absolute error: 0.22112\n",
      "epoch: 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd1129c45b343fd80f2294c6b016813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.08111\n",
      "Mean absolute error: 0.21343\n",
      "epoch: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f92135905f4e86bf953396c930ec11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.07782\n",
      "Mean absolute error: 0.20821\n",
      "epoch: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4eacd697004b39a6f5ba91cd64f7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.07850\n",
      "Mean absolute error: 0.20930\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "EPOCHS = 25\n",
    "model = SalaryPredictor().to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "if os.path.exists(\"best_model.pt\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "\n",
    "if os.path.exists(\"train\"):\n",
    "    it = len(os.listdir(\"train\"))\n",
    "else:\n",
    "    it = 0\n",
    "    os.mkdir(\"train\")\n",
    "\n",
    "path = f\"train/exp{it}\" # structure inspired by YOLO experiment structure\n",
    "\n",
    "os.mkdir(path)\n",
    "\n",
    "best = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=device)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(model.state_dict(), f\"{path}/epoch{epoch}.pt\")\n",
    "    mse, mae = print_metrics(model, data_val, device=device)\n",
    "    if best is None or mse < best:\n",
    "        best = mse\n",
    "        torch.save(model.state_dict(), f\"{path}/best_model.pt\")\n",
    "\n",
    "if os.path.exists(\"best_model.pt\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "    mse, mae = print_metrics(model, data_val, device=device)\n",
    "    if best > mse:\n",
    "        shutil.copy(f\"{path}/best_model.pt\", \"best_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A, B, and E together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAttnEncoder(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), out_size=64, embed_size=128): # Greater embed size than original\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(n_tokens, embed_size)\n",
    "        \n",
    "        # Triple the number of convolutions and add batch normalization to CNN architecture\n",
    "        self.conv1 = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(out_size)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(out_size)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(embed_size, out_size, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(out_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3) # Add dropout to CNN architecture\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.attn = nn.Linear(out_size, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.emb(X).transpose(1, 2)\n",
    "        \n",
    "        h1 = self.relu(self.bn1(self.conv1(h)))\n",
    "        h2 = self.relu(self.bn2(self.conv2(h)))\n",
    "        h3 = self.relu(self.bn3(self.conv3(h)))\n",
    "\n",
    "        h = h1+h2+h3\n",
    "\n",
    "        attn_scores = self.attn(h.transpose(1, 2)).squeeze(2)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "\n",
    "        return self.dropout(torch.bmm(attn_weights.unsqueeze(1), h.transpose(1, 2)).squeeze(1))\n",
    "\n",
    "\n",
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=100):\n",
    "        super().__init__()\n",
    "        self.title_encoder = ConvAttnEncoder(n_tokens, out_size=hid_size, embed_size=hid_size) # during the lecture practice, Prof only used the title_encoder, but the graph said to also have a description encoder \n",
    "        #self.description_encoder = ConvAttnEncoder(n_tokens, out_size=hid_size, embed_size=hid_size)\n",
    "        self.fc = nn.Linear(hid_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.title_encoder(batch[\"Title\"])).squeeze()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalaryPredictor().to(device)\n",
    "batch = make_batch(data_train[:100], device=device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dummy_pred = model(batch)\n",
    "dummy_loss = criterion(dummy_pred, batch[TARGET_COLUMN])\n",
    "assert dummy_pred.shape == torch.Size([100])\n",
    "assert len(torch.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert dummy_loss.ndim == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:42, 75.44it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.27798\n",
      "Mean absolute error: 0.42962\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:30, 81.12it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.16394\n",
      "Mean absolute error: 0.31044\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:30, 81.43it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.16088\n",
      "Mean absolute error: 0.31653\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:40, 76.48it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.12699\n",
      "Mean absolute error: 0.26833\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:28, 82.52it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.12447\n",
      "Mean absolute error: 0.26648\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12239it [02:21, 86.29it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results:\n",
      "Mean square error: 0.12249\n",
      "Mean absolute error: 0.26595\n",
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 2877/12238 [00:33<01:50, 84.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m     29\u001b[0m         iterate_minibatches(data_train, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, device\u001b[38;5;241m=\u001b[39mdevice)),\n\u001b[1;32m     30\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_train) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m BATCH_SIZE\n\u001b[1;32m     31\u001b[0m     ):\n\u001b[1;32m     32\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, batch[TARGET_COLUMN])\n",
      "File \u001b[0;32m~/Documents/cs539/RIT_LLM/.venv/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[146], line 9\u001b[0m, in \u001b[0;36miterate_minibatches\u001b[0;34m(data, batch_size, shuffle, cycle, device, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(indices)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(indices), batch_size):\n\u001b[0;32m----> 9\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mmake_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cycle: \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[139], line 27\u001b[0m, in \u001b[0;36mmake_batch\u001b[0;34m(data, max_len, word_dropout, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     26\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m as_matrix(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, max_len)\n\u001b[0;32m---> 27\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFullDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mas_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFullDescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategorical\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m categorical_vectorizer\u001b[38;5;241m.\u001b[39mtransform(data[categorical_columns]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mdict\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m#.sum(axis=1) #.argmax(axis=1)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m batch[TARGET_COLUMN] \u001b[38;5;241m=\u001b[39m data[TARGET_COLUMN]\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[135], line 12\u001b[0m, in \u001b[0;36mas_matrix\u001b[0;34m(sequences, max_len)\u001b[0m\n\u001b[1;32m     10\u001b[0m matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;28mlen\u001b[39m(sequences), max_len), np\u001b[38;5;241m.\u001b[39mint32(PAD_IX))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,seq \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sequences):\n\u001b[0;32m---> 12\u001b[0m     row_ix \u001b[38;5;241m=\u001b[39m [token_to_id\u001b[38;5;241m.\u001b[39mget(word, UNK_IX) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m seq[:max_len]]\n\u001b[1;32m     13\u001b[0m     matrix[i, :\u001b[38;5;28mlen\u001b[39m(row_ix)] \u001b[38;5;241m=\u001b[39m row_ix\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n",
      "Cell \u001b[0;32mIn[135], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;28mlen\u001b[39m(sequences), max_len), np\u001b[38;5;241m.\u001b[39mint32(PAD_IX))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,seq \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sequences):\n\u001b[0;32m---> 12\u001b[0m     row_ix \u001b[38;5;241m=\u001b[39m [\u001b[43mtoken_to_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUNK_IX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m seq[:max_len]]\n\u001b[1;32m     13\u001b[0m     matrix[i, :\u001b[38;5;28mlen\u001b[39m(row_ix)] \u001b[38;5;241m=\u001b[39m row_ix\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "EPOCHS = 25\n",
    "model = SalaryPredictor().to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "if os.path.exists(\"best_model.pt\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "\n",
    "if os.path.exists(\"train\"):\n",
    "    it = len(os.listdir(\"train\"))\n",
    "else:\n",
    "    it = 0\n",
    "    os.mkdir(\"train\")\n",
    "\n",
    "path = f\"train/exp{it}\" # structure inspired by YOLO experiment structure\n",
    "\n",
    "os.mkdir(path)\n",
    "\n",
    "best = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=device)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(model.state_dict(), f\"{path}/epoch{epoch}.pt\")\n",
    "    mse, mae = print_metrics(model, data_val, device=device)\n",
    "    if best is None or mse < best:\n",
    "        best = mse\n",
    "        torch.save(model.state_dict(), f\"{path}/best_model.pt\")\n",
    "\n",
    "if os.path.exists(\"best_model.pt\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "    mse, mae = print_metrics(model, data_val, device=device)\n",
    "    if best > mse:\n",
    "        shutil.copy(f\"{path}/best_model.pt\", \"./best_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgND2_E5qPPc"
   },
   "source": [
    "### A short report\n",
    "\n",
    "Please tell us what you did and how did it work.\n",
    "\n",
    "```\n",
    "For started, I added the rest of the diagram's layers to the Salary Predictor class in the practice section. When using both Title and Description encoding, it was able to generate a loss of ~0.135 within the first epoch as opposed to ~0.278 MSE during epoch 0 when only using the Title (and still only getting 0.122 by epoch 6); adding the Categorical Encoder made it better still at 0.125 during the first epoch and as low as 0.092 by the third epoch, which is already amazing as far as an MSE score goes. \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uYKrVlEYmfn"
   },
   "source": [
    "### Bonus part: explaining model predictions\n",
    "\n",
    "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
    "\n",
    "There are, however, some ways to look inside the black box:\n",
    "* Seeing how model responds to input perturbations\n",
    "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
    "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
    "\n",
    "Today we gonna try the first method just because it's the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0jjzoDZYmfn"
   },
   "outputs": [],
   "source": [
    "def explain(model, sample, col_name='Title'):\n",
    "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
    "    sample = dict(sample)\n",
    "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
    "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
    "\n",
    "    for drop_i in range(len(sample_col_tokens)):\n",
    "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
    "                                                   for i, tok in enumerate(sample_col_tokens))\n",
    "\n",
    "    *predictions_drop_one_token, baseline_pred = model(make_batch(data_drop_one_token, device=device)).detach().cpu()\n",
    "    diffs = baseline_pred - torch.Tensor(predictions_drop_one_token)\n",
    "    return list(zip(sample_col_tokens, diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgGBYzDeYmfo"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display_html\n",
    "\n",
    "\n",
    "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
    "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
    "              font_style=\"font-size:14px;\"\n",
    "             ):\n",
    "\n",
    "    def get_color_hex(weight):\n",
    "        rgba = cmap(1. / (1 + np.exp(float(weight))), bytes=True)\n",
    "        return '#%02X%02X%02X' % rgba[:3]\n",
    "\n",
    "    tokens_html = [\n",
    "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
    "        for token, weight in tokens_and_weights\n",
    "    ]\n",
    "\n",
    "\n",
    "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
    "    if display:\n",
    "        display_html(HTML(raw_html))\n",
    "\n",
    "    return raw_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXn_Gs2MYmfo"
   },
   "outputs": [],
   "source": [
    "i = 36605\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5xTTvjvYmfo"
   },
   "outputs": [],
   "source": [
    "i = 12077\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXw3hbNlYmfo"
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(len(data))\n",
    "print(\"Index:\", i)\n",
    "print(\"Salary (gbp):\", np.expm1(model(make_batch(data.iloc[i: i+1], device=device)).detach().cpu()))\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbuK6LFHYmfo"
   },
   "source": [
    "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtiXVOKUPbGV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "002e6a05cccf4b75b67564c9dde9acc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07bf9c7fe1f4431098997cc7fa1a7c92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9ae53a2b2714fdbb8b03a75e470d702",
       "IPY_MODEL_36ce70f9f0b9422181b00e391c71fb87",
       "IPY_MODEL_f7acd5693d824bfdaa2118f3695ab9a9"
      ],
      "layout": "IPY_MODEL_2258576006254a24a7fd12625b8134b0"
     }
    },
    "07da6a0467e34232a938ffd368992f91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_874af4a3d028453e988ab7901b1559ff",
      "placeholder": "",
      "style": "IPY_MODEL_bae5a5a2f45e495ab435106703275e03",
      "value": "12239/?[18:43&lt;00:00,12.22it/s]"
     }
    },
    "0a1dd2f13bb347af9943bb9d2e8defa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_002e6a05cccf4b75b67564c9dde9acc6",
      "placeholder": "",
      "style": "IPY_MODEL_a4725d892023410ba0eccfc7422b8589",
      "value": ""
     }
    },
    "1a46d9d0c1e846f9b9be0639f0a8bdc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a57b88984df4542901af43d9c89cfa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2258576006254a24a7fd12625b8134b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36ce70f9f0b9422181b00e391c71fb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c19ed6fca1540a8b269fe1120902736",
      "max": 12238,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_982f9d4adbc6430f95c280beea6e1a20",
      "value": 12238
     }
    },
    "44679b989f82453c82485e35474a3f96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ede4f9569704369b71bbec4535d56f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f604b78cea34114a2f5e60b87b30a51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50840c75126a42db8137d083e03dbb5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5aa5ad1051694ceb939190dabb97cb84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "608b9441525b48fbaedfedba55aa392c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6224403a65da420c909c527dbdcd6f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63ffb20d56c24910a0c22f021831d8e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a1dd2f13bb347af9943bb9d2e8defa0",
       "IPY_MODEL_d97af5fd168846fb8c9f21d4ff5bebce",
       "IPY_MODEL_bd4231ce5c5c4c1086fb69ecdd716348"
      ],
      "layout": "IPY_MODEL_f6a30814f1f2425da67e3135e993aa8a"
     }
    },
    "6a2d7353590a416c81d1e125314ff8e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c975f5e9ba148fe878d7780855a372a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7227ed89cdb14f5ca2333e45cc369d3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f595c96662b4b18a7f84630f3217a6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "874af4a3d028453e988ab7901b1559ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a5ab0322f574c3387f8340dbebb1e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce0b75adbf0f4722a56a4955ee8f17e7",
       "IPY_MODEL_f26a5a04c6464ed89551143ab901385b",
       "IPY_MODEL_fb1316f2e5ca440c804d6ef54f19c5a1"
      ],
      "layout": "IPY_MODEL_7227ed89cdb14f5ca2333e45cc369d3d"
     }
    },
    "8c19ed6fca1540a8b269fe1120902736": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "982f9d4adbc6430f95c280beea6e1a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a2902d053080478b82c7b4f7eb9195e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4725d892023410ba0eccfc7422b8589": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2dbb3fd673346b2b8489a2b11446745": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bae5a5a2f45e495ab435106703275e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd4231ce5c5c4c1086fb69ecdd716348": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1c33b713ba745aaba902f3f59928ba4",
      "placeholder": "",
      "style": "IPY_MODEL_4ede4f9569704369b71bbec4535d56f0",
      "value": "12239/?[18:47&lt;00:00,11.25it/s]"
     }
    },
    "cabc6658d39846b389b3f434cd1213ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc29c27860f94bb381b7223314ced3f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce0b75adbf0f4722a56a4955ee8f17e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a2d7353590a416c81d1e125314ff8e7",
      "placeholder": "",
      "style": "IPY_MODEL_cc29c27860f94bb381b7223314ced3f0",
      "value": "1%"
     }
    },
    "d3950bf20ad34e1bae4357fe76487c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee94526e72e749d2b0475f2be6803ceb",
       "IPY_MODEL_ed17fe5250f7444f9e5c724b454c5011",
       "IPY_MODEL_07da6a0467e34232a938ffd368992f91"
      ],
      "layout": "IPY_MODEL_4f604b78cea34114a2f5e60b87b30a51"
     }
    },
    "d97af5fd168846fb8c9f21d4ff5bebce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a46d9d0c1e846f9b9be0639f0a8bdc0",
      "max": 12238,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6224403a65da420c909c527dbdcd6f76",
      "value": 12238
     }
    },
    "dec4444d3d354e3abf76d10d25fb14ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1c33b713ba745aaba902f3f59928ba4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed17fe5250f7444f9e5c724b454c5011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cabc6658d39846b389b3f434cd1213ab",
      "max": 12238,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c975f5e9ba148fe878d7780855a372a",
      "value": 12238
     }
    },
    "ee94526e72e749d2b0475f2be6803ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f410787f3b264c67a70a167df2c70e20",
      "placeholder": "",
      "style": "IPY_MODEL_dec4444d3d354e3abf76d10d25fb14ff",
      "value": ""
     }
    },
    "f26a5a04c6464ed89551143ab901385b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44679b989f82453c82485e35474a3f96",
      "max": 12238,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5aa5ad1051694ceb939190dabb97cb84",
      "value": 76
     }
    },
    "f410787f3b264c67a70a167df2c70e20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6a30814f1f2425da67e3135e993aa8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7acd5693d824bfdaa2118f3695ab9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2902d053080478b82c7b4f7eb9195e1",
      "placeholder": "",
      "style": "IPY_MODEL_608b9441525b48fbaedfedba55aa392c",
      "value": "12239/?[18:24&lt;00:00,13.36it/s]"
     }
    },
    "f9ae53a2b2714fdbb8b03a75e470d702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2dbb3fd673346b2b8489a2b11446745",
      "placeholder": "",
      "style": "IPY_MODEL_50840c75126a42db8137d083e03dbb5c",
      "value": ""
     }
    },
    "fb1316f2e5ca440c804d6ef54f19c5a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f595c96662b4b18a7f84630f3217a6f",
      "placeholder": "",
      "style": "IPY_MODEL_1a57b88984df4542901af43d9c89cfa5",
      "value": "76/12238[00:06&lt;15:52,12.77it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
